{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 4 - Data Analysis pipelines using a shell script\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "By the end of the lecture, students are expected to be able to:\n",
    "- Create a data analysis pipeline using R, Python and the Unix shell to run multiple scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data analysis pipelines\n",
    "\n",
    "- As analysis grows in length and complexity, one literate code document generally is not enough\n",
    "\n",
    "- To improve code report readability (and code reproducibility and modularity) it is better to abstract at least parts of the code away (e.g, to scripts)\n",
    "\n",
    "- These scripts save figures and tables that will be imported into the final report\n",
    "\n",
    "<img src=\"img/scripts.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{figure} img/scripts.png\n",
    "---\n",
    "width: 800px\n",
    "name: scripts\n",
    "align: left\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a Data Analysis pipeline using a Shell script tutorial\n",
    "adapted from [Software Carpentry](http://software-carpentry.org/)\n",
    "\n",
    "To illustrate how to make a data analysis pipeline using a shell script to drive other scripts, we will work through an example together. Here are some set-up instructions so that we can do this together:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Set-up instructions\n",
    "\n",
    "- Download [data_analysis_pipeline_eg-1.0.zip](https://github.com/ttimbers/data_analysis_pipeline_eg/archive/v1.0.zip)\n",
    "- Unzip it and change into the `data_analysis_pipeline_eg-1.0` directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's do some analysis!\n",
    "\n",
    "Suppose we have a script, `wordcount.py`, that reads in a text file,\n",
    "counts the words in this text file, and outputs a data file:\n",
    "\n",
    "~~~\n",
    "$ python src/wordcount.py data/isles.txt results/isles.dat\n",
    "~~~\n",
    "\n",
    "If we view the first 5 rows of the data file using `head`,\n",
    "\n",
    "~~~\n",
    "$ head -5 results/isles.dat\n",
    "~~~\n",
    "\n",
    "we can see that the file consists of one row per word. Each row shows the word itself,\n",
    "the number of occurrences of that word, and the number of occurrences as a percentage of\n",
    "the total number of words in the text file.\n",
    "\n",
    "~~~\n",
    "the 3822 6.7371760973\n",
    "of 2460 4.33632998414\n",
    "and 1723 3.03719372466\n",
    "to 1479 2.60708619778\n",
    "a 1308 2.30565838181\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we also have a script, `plotcount.py`, that reads in a data\n",
    "file and save a plot of the 10 most frequently occurring words:\n",
    "\n",
    "~~~\n",
    "$ python src/plotcount.py results/isles.dat results/figure/isles.png\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together these scripts implement a data analysis pipeline:\n",
    "\n",
    "1. Read a data file.\n",
    "2. Perform an analysis on this data file.\n",
    "3. Write the analysis results to a new file.\n",
    "4. Plot a graph of the analysis results.\n",
    "\n",
    "To document how we'd like the analysis to be run, so we (and others) have a record and\n",
    "can replicate it, we will build a shell script called `run_all.sh`. Let's work to try\n",
    "to build this pipeline so it does all that!\n",
    "\n",
    "```\n",
    "# run_all.sh\n",
    "# Tiffany Timbers, Nov 2017\n",
    "#\n",
    "# This driver script completes the textual analysis of\n",
    "# 3 novels and creates figures on the 10 most frequently\n",
    "# occuring words from each of the 3 novels. This script\n",
    "# takes no arguments.\n",
    "#\n",
    "# Usage: bash run_all.sh\n",
    "\n",
    "# perform wordcout on novels\n",
    "python src/wordcount.py data/isles.txt results/isles.dat\n",
    "\n",
    "# create plots\n",
    "python src/plotcount.py results/isles.dat results/figure/isles.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually have 4 books that we want to analyze, and then put the figures in a report. \n",
    "\n",
    "1. Read a data file.\n",
    "2. Perform an analysis on this data file.\n",
    "3. Write the analysis results to a new file.\n",
    "4. Plot a graph of the analysis results.\n",
    "5. Save the graph as an image, so we can put it in a paper.\n",
    "\n",
    "Let's extend our shell script to do that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# run_all.sh\n",
    "# Tiffany Timbers, Nov 2018\n",
    "\n",
    "# This driver script completes the textual analysis of\n",
    "# 3 novels and creates figures on the 10 most frequently\n",
    "# occuring words from each of the 3 novels. This script\n",
    "# takes no arguments.\n",
    "\n",
    "# example usage:\n",
    "# bash run_all.sh\n",
    "\n",
    "# count the words\n",
    "python src/wordcount.py data/isles.txt results/isles.dat\n",
    "python src/wordcount.py data/abyss.txt results/abyss.dat\n",
    "python src/wordcount.py data/last.txt results/last.dat\n",
    "python src/wordcount.py data/sierra.txt results/sierra.dat\n",
    "\n",
    "# create the plots\n",
    "python src/plotcount.py results/isles.dat results/figure/isles.png\n",
    "python src/plotcount.py results/abyss.dat results/figure/abyss.png\n",
    "python src/plotcount.py results/last.dat results/figure/last.png\n",
    "python src/plotcount.py results/sierra.dat results/figure/sierra.png\n",
    "\n",
    "# write the report\n",
    "Rscript -e \"rmarkdown::render('doc/count_report.Rmd')\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another example:\n",
    "\n",
    "From the [breast cancer prediction example analysis repo](https://github.com/ttimbers/breast_cancer_predictor), here is a data analysis pipeline using a shell script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "# run_all.sh\n",
    "# Tiffany Timbers, Jan 2020\n",
    "\n",
    "# download data\n",
    "python src/download_data.py --out_type=feather --url=https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wpbc.data --out_file=data/raw/wdbc.feather\n",
    "\n",
    "# run eda report\n",
    "Rscript -e \"rmarkdown::render('src/breast_cancer_eda.Rmd')\"\n",
    "\n",
    "# pre-process data \n",
    "Rscript src/pre_process_wisc.r --input=data/raw/wdbc.feather --out_dir=data/processed \n",
    "\n",
    "# create exploratory data analysis figure and write to file \n",
    "Rscript src/eda_wisc.r --train=data/processed/training.feather --out_dir=results\n",
    "\n",
    "# tune model\n",
    "Rscript src/fit_breast_cancer_predict_model.r --train=data/processed/training.feather --out_dir=results\n",
    "\n",
    "# test model\n",
    "Rscript src/breast_cancer_test_results.r --test=data/processed/test.feather --out_dir=results\n",
    "\n",
    "# render final report\n",
    "Rscript -e \"rmarkdown::render('doc/breast_cancer_predict_report.Rmd', output_format = 'github_document')\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Closing thoughts\n",
    "\n",
    "- What are the advantages to using a data analysis pipeline?\n",
    "\n",
    "- How \"good\" is a shell script as a data analysis pipeline? What might not be ideal about this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's next?\n",
    "\n",
    "- Using a smart dependency tool, GNU Make, to make smarter pipelines."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md,ipynb",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}